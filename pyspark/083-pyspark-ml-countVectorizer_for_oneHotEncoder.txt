
Target: convert a array of strings containing arbitrary number of elements into OneHotEncoder format.

An interesting way to create a list of OneHotEncoder by using pyspark.ml.feature.CountVectorizer

+ Just need to remove potential duplicate items in the array

REF:https://stackoverflow.com/questions/58010126/pyspark-string-array-of-dynamic-length-in-dataframe-column-to-onehot-encoded/58012725#58012725

Data Setup:

    from pyspark.ml.feature import CountVectorizer
    from pyspark.sql.functions import array_distinct, udf
    
    df = spark.createDataFrame([
            (["ABC","def","ghi"],)
          , (["Jkl","ABC","def"],)
          , (["Xyz","ABC"],)
        ], ['arr']
    )
    
Remove duplicates in the `arr` column

    # remove duplicate items in the same array
    df = df.withColumn('arr', array_distinct('arr'))
    
Set up CountVectorizer model and check the model.vocabulary
   
    cv = CountVectorizer(inputCol='arr', outputCol='c1')
    
    model = cv.fit(df)
    
    vocabulary = model.vocabulary
    # [u'ABC', u'def', u'Xyz', u'ghi', u'Jkl']

Create a UDF to convert a vector to array:

    udf_to_array = udf(lambda v: v.toArray().tolist(), 'array<double>')
    

Transform the df, get the vector column in `c1` its corresponding array column `c2`
check the `c2` list using the model.vocabulary.
    
    df1 = model.transform(df)
    
    df1.withColumn('c2', udf_to_array('c1')) \
       .select('*', *[ F.col('c2')[i].astype('int').alias(vocabulary[i]) for i in range(len(vocabulary))]) \
       .show()
    +---------------+--------------------+---+---+---+---+---+
    |            arr|                  c1|ABC|def|Xyz|ghi|Jkl|
    +---------------+--------------------+---+---+---+---+---+
    |[ABC, def, ghi]|(5,[0,1,3],[1.0,1...|  1|  1|  0|  1|  0|
    |[Jkl, ABC, def]|(5,[0,1,4],[1.0,1...|  1|  1|  0|  0|  1|
    |     [Xyz, ABC]| (5,[0,2],[1.0,1.0])|  1|  0|  1|  0|  0|
    +---------------+--------------------+---+---+---+---+---+
    
