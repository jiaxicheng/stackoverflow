
https://stackoverflow.com/questions/56409454/casting-a-column-to-json-dict-and-flattening-json-values-in-a-column-in-pyspark/56409889?noredirect=1#comment99918287_56409889

df = spark.read.csv('file:///home/hdfs/test/pyspark/json-3.txt', sep='|').toDF('col1','col2')

cols = ['test1:subtest1', 'test1:subtest2']

key_schema = df.select(F.schema_of_json('{"test1:subtest1":[{"Id":"17","cName":"c1","pScore":0.00203}]}').alias('schema')).first().schema
>>> key_schema
u'struct<test1:subtest1:array<struct<Id:string,cName:string,pScore:double>>>'

schema = u'struct<' + ','.join([r'`{}`:array<struct<Id:string,cName:string,pScore:double>>'.format(c) for c in cols]) + r'>'

>>> schema
u'struct<`test1:subtest1`:array<struct<Id:string,cName:string,pScore:double>>,`test1:subtest2`:array<struct<Id:string,cName:string,pScore:double>>>'

# 
df1 = df.withColumn('data', F.from_json('col2', schema)).select('col1', 'data.*')

>>> df1.printSchema()
root
 |-- col1: string (nullable = true)
 |-- test1:subtest1: array (nullable = true)
 |    |-- element: struct (containsNull = true)
 |    |    |-- Id: string (nullable = true)
 |    |    |-- cName: string (nullable = true)
 |    |    |-- pScore: double (nullable = true)
 |-- test1:subtest2: array (nullable = true)
 |    |-- element: struct (containsNull = true)
 |    |    |-- Id: string (nullable = true)
 |    |    |-- cName: string (nullable = true)
 |    |    |-- pScore: double (nullable = true)


>>> df1.show(2,0)
+------+--------------+--------------------+
|col1  |test1:subtest1|test1:subtest2      |
+------+--------------+--------------------+
|test:1|[[17, c1,]]   |[[01, c2,]]         |
|test:2|null          |[[18, c13, 0.00203]]|
+------+--------------+--------------------+


df_new = reduce(lambda x,y: x.union(y)
          , [ df1.select('col1', F.lit(c).alias('col2'), F.explode(F.col(c)).alias('arr')) for c in cols ]
        ).select('col1', 'col2', 'arr.*')


df_new = df1.select('col1', F.lit('test1:subtest1').alias('col2'), F.explode(F.col('test1:subtest1')).alias('arr')) \
            .union(
                df1.select('col1',F.lit('test1:subtest2'), F.explode(F.col('test1:subtest2')))
           ).dropna(subset=['arr']) \
            .select('col1', 'col2', 'arr.*')

>>> df_new.show()
+------+--------------+---+-----+-------+
|  col1|          col2| Id|cName| pScore|
+------+--------------+---+-----+-------+
|test:1|test1:subtest1| 17|   c1|   null|
|test:1|test1:subtest2| 01|   c2|   null|
|test:2|test1:subtest2| 18|  c13|0.00203|
+------+--------------+---+-----+-------+




https://stackoverflow.com/questions/56409454/casting-a-column-to-json-dict-and-flattening-json-values-in-a-column-in-pyspark/56409889?noredirect=1#comment99918287_56409889


structure = df.select(F.schema_of_json('{"test1:subtest2":[{"Id":"18","cName":"c13","pScore":0.00203}]}').alias('schema')).first().schema

>>> structure
u'struct<test1:subtest2:array<struct<Id:string,cName:string,pScore:double>>>'

schema = u'struct<' + ','.join([r'`{}`:array<struct<Id:string,cName:string,pScore:double>>'.format(c) for c in cols]) + r'>'

>>> schema
u'struct<`test1`:array<struct<Id:string,cName:string,pScore:double>>,`test8`:array<struct<Id:string,cName:string,pScore:double>>,`test1:subtest2`:array<struct<Id:string,cName:string,pScore:double>>>'




