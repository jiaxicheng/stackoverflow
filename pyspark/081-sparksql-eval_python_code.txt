evaluate a column containing Python code, and run it with SQL:
notice that this only works with Python expression, not SQL expression)

    df = spark.read.csv("/home/xicheng/test/eval-1.txt", header=True, inferSchema=True)
    
    spark.udf.register('my_expr', lambda x, var1, var2: eval(x), 'boolean')
    
    df.selectExpr('*', 'my_expr(expr,var1,var2) as flag').show(truncate=False)
    #DataFrame[expr: string, var1: int, var2: int, flag: boolean]
    +-------------------------+----+----+-----+
    |expr                     |var1|var2|flag |
    +-------------------------+----+----+-----+
    |var1 > 7                 |9   |0   |true |
    |var1 > 7                 |6   |0   |false|
    |var1 > 7                 |2   |0   |false|
    |var1 > 7                 |12  |0   |true |
    |(var1 == 3) & (var2 >= 0)|3   |-2  |false|
    |(var1 == 3) & (var2 >= 0)|9   |0   |false|
    |(var1 == 3) & (var2 >= 0)|3   |1   |true |
    |(var1 == 3) & (var2 >= 0)|9   |-1  |false|
    |(var1 == 2) & (var2 >= 0)|9   |0   |false|
    +-------------------------+----+----+-----+
    
    
REF:
 (1) https://stackoverflow.com/questions/62478849/pyspark-pass-a-value-from-another-column-as-the-parameter-of-spark-function
 (2) https://stackoverflow.com/questions/49999119/how-to-evaluate-expressions-that-are-the-column-values/50010599
 (3) https://stackoverflow.com/questions/57657692/pyspark-process-expression-in-dataframe 


