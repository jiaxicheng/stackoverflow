Use backslash inside String literals:


---
Example-1: escape backslashes in Scala string literals (including regex patterns)
  REF: https://stackoverflow.com/a/65403993/9510729
  Points being: String literals (including regex patterns) are not escaped, to keep literal backslashes
    inside strings or patterns, you will have to use backslash to manually escape them.

  Example:

    val df = Seq("urn:fb:xyx:266730227", "urn:fb:pqr:(urn:fb:abc:6217401,10444030746)").toDF("value")
    df.createOrReplaceTempView("tbl")
  
    // pattern as regular string literal
    df.withColumn("p_id", regexp_extract($"value", "(\\d+)", 1)).show(false)
    +-------------------------------------------+---------+
    |value                                      |p_id     |
    +-------------------------------------------+---------+
    |urn:fb:xyx:266730227                       |266730227|
    |urn:fb:pqr:(urn:fb:abc:6217401,10444030746)|6217401  |
    +-------------------------------------------+---------+

this can be overcome by using raw string or multi-Line string on the pattern:

    // pattern as raw string
    df.withColumn("p_id", regexp_extract($"value", raw"(\d+)", 1)).show(false)
    +-------------------------------------------+---------+
    |value                                      |p_id     |
    +-------------------------------------------+---------+
    |urn:fb:xyx:266730227                       |266730227|
    |urn:fb:pqr:(urn:fb:abc:6217401,10444030746)|6217401  |
    +-------------------------------------------+---------+

    // pattern as multi-Line string where backslash is not escaped
    df.withColumn("p_id", regexp_extract($"value", """(\d+)""", 1)).show(false)
    +-------------------------------------------+---------+
    |value                                      |p_id     |
    +-------------------------------------------+---------+
    |urn:fb:xyx:266730227                       |266730227|
    |urn:fb:pqr:(urn:fb:abc:6217401,10444030746)|6217401  |
    +-------------------------------------------+---------+


When **backslashes** and *regexp_extract*(*regexp_replace*, *split*, *str_to_map* etc.) are shown inside an SQL 
expression, like `expr()`, `df.selectExpr()`, `spark.sql()`, `df.filter()`, `df.where()` etc., we will have to 
double-escape the backslashes. for example:

    // regular string literals
    spark.sql("select *, regexp_extract(value, '(\\\\d+)', 1) as p_id from tbl").show
    // raw string to SQL expression
    spark.sql(raw"select *, regexp_extract(value, '(\\d+)', 1) as p_id from tbl").show
    // multi-Line string to SQL expression
    spark.sql("""select *, regexp_extract(value, '(\\d+)', 1) as p_id from tbl""").show

    df.withColumn("p_id", expr("regexp_extract(value, '(\\\\d+)', 1)")).show(false)
    df.withColumn("p_id", expr(raw"regexp_extract(value, '(\\d+)', 1)")).show(false)
    df.withColumn("p_id", expr("""regexp_extract(value, '(\\d+)', 1)""")).show(false)

    df.filter("value rlike '\\\\d'").show
    df.filter(raw"value rlike '\\d'").show
    df.filter("""value rlike '\\d'""").show

For spark 2.0+, this can be surpassed by setting *spark.sql.parser.escapedStringLiterals*=**true** (default is `false`)
see [here](https://github.com/apache/spark/blob/branch-3.0/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/regexpExpressions.scala#L69)

>   val ESCAPED_STRING_LITERALS = buildConf("spark.sql.parser.escapedStringLiterals")
>    .internal()
>    .doc("When true, string literals (including regex patterns) remain escaped in our SQL " +
>      "parser. The default is false since Spark 2.0. Setting it to true can restore the behavior " +
>      "prior to Spark 2.0.")
>    .version("2.2.1")
>    .booleanConf
>    .createWithDefault(false)

    spark.conf.set("spark.sql.parser.escapedStringLiterals", "true")

    df.withColumn("p_id", expr("regexp_extract(value, '(\\d+)', 1)")).show(false)
    df.withColumn("p_id", expr(raw"regexp_extract(value, '(\d+)', 1)")).show(false)
    spark.sql("select *, regexp_extract(value, '(\\d+)', 1) as p_id from tbl").show
    spark.sql("""select *, regexp_extract(value, '(\d+)', 1) as p_id from tbl""").show
    df.filter(raw"value rlike '\d'").show

**Side-note: the above discussion is about escaping the **literal** backslashes inside strings, in case er want the 
actual escaped chars (i.e. newline `\n`, TAB `\t`, NUL char `\0` or `\u0000` etc), then no extra backslash is 
required, for example:

    // merge multiple lines into one line
    spark.sql("select *, regexp_replace(x,'\n+',',') as y from values ('1,2\n3\n\n4') as (x)").show
    // split string into an array using NUL char or/and TAB
    spark.sql("select *, split(x,'[\t\u0000]+') as y from values ('s\u0000x\ty\tz') as (x)").show

  Reference: 
    [1] https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala#L601
    [2] https://github.com/apache/spark/blob/branch-3.0/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/regexpExpressions.scala#L69


  Notes: the above is for Scala code, for Python code:
    (1) Raw string is r"..."
    (2) Multi-line string will escape backslash, so it's not working the same as Scala, need to use
        r-string as well for multi-Line string: r"""..."""



Example-2: backslashes for escaped chars
 # discuss how escape works

    df = spark.createDataFrame([("1,2\n3\n\n4",)]).toDF("value")

    df.selectExpr("*", "regexp_replace(value,'\n+',',') as vals")         <-- work when 1 backslashes
    df.selectExpr("*", "regexp_replace(value,'\\\\\\\n+',',') as vals")   <-- work when <= 7 backslashes
    df.selectExpr("*", "regexp_replace(value,'\\\\\\\\n+',',') as vals")  <-- not work > 7 backslashes

 How this happens: 1-7 backslashes work?
  (1) escape on the SQL expression: 
     1: '\n' becomes newline
     7: '\\\\\\\n' becomes '\\\' + newline
     8: '\\\\\\\\n' becomes '\\\\n'

 (2) escape with the regex pattern:
     1: newline is still newline (nothing to escape)
     7: '\\\' + newline becomes '\' + newline (in regex pattern, this will be newline)   
     8: '\\\\n' becomes '\\n' becomes backslash + `n`
 
  Note: `\` followed by an newline inside a string literal is always a newline
        `\` followed by a newline inside a pattern matches newline as well

  In Raw-string:

    df.selectExpr("*", r"regexp_replace(value,'\n+',',') as vals")         1 works     <newline>+
    df.selectExpr("*", r"regexp_replace(value,'\\n+',',') as vals")        2 works     \n+
    df.selectExpr("*", r"regexp_replace(value,'\\\n+',',') as vals")       3 works     \<newline>+
    df.selectExpr("*", r"regexp_replace(value,'\\\\n+',',') as vals")      4+ not work \\n+



