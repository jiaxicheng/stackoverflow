    
https://stackoverflow.com/questions/58937997/pyspark-merge-dataframe-rows-one-array-is-contained-in-another

Use a self join to find all rows which have array values a subset of array from another row:

 + use `size(array_except(d2.cycle, d1.cycle))==0` to find subset
 + use `size(d2.cycle) < size(d1.cycle)` exclude self


After we have this list, take a left_anti join to the original df and then use sort_array
and drop_duplicates to remove the array with the same items:

    df = spark.createDataFrame([ 
         (["1", "2","3","4"], ), 
         (["1","2","3"], ), 
         (["2","1","3"], ), 
         (["2","3","4","1"], ), 
         (["2","3","5"],), 
         (["1","3","4"],), 
         (["6","7"], ) 
    ], ['cycle', ]) 
    
    from pyspark.sql.functions import expr

    # Sample df:
    df.show()                                                                                                          
    #+------------+
    #|       cycle|
    #+------------+
    #|[1, 2, 3, 4]|
    #|   [1, 2, 3]|
    #|   [2, 1, 3]|
    #|[2, 3, 4, 1]|
    #|   [2, 3, 5]|
    #|   [1, 3, 4]|
    #|      [6, 7]|
    #+------------+
    
    Method-1: 

    # get df_sub containing all rows with array values from array of another Row
    df_sub = df.alias('d1').join(
          df.alias('d2')
        , expr('size(array_except(d2.cycle, d1.cycle))==0 AND size(d2.cycle) < size(d1.cycle)')
    ).select('d2.cycle')


    Method-2: use udf:
    # if add all logic into is_subset(), will have the following error
    #Detected implicit cartesian product for INNER join between logical plans

    from pyspark.sql.functions import udf

    @udf('boolean')
    def is_subset(a1, a2):
      try:
        return set(a1).issubset(set(a2)) 
      except:
        return False

    df_sub = df.alias('d1').join(
            df.alias('d2')
          , expr('size(d2.cycle) < size(d1.cycle)') & is_subset('d2.cycle', 'd1.cycle')
        ).select('d2.cycle')


Step-2:
    
    # take a left_anti join to exclude all such Rows
    df.join(df_sub, on=['cycle'], how='left_anti').show()                                                              
    #+------------+                                                                  
    #|       cycle|
    #+------------+
    #|[1, 2, 3, 4]|
    #|   [2, 3, 5]|
    #|      [6, 7]|
    #|[2, 3, 4, 1]|
    #+------------+
    
    # sort array and drop_duplicates
    df_new = df.join(df_sub , on=['cycle'], how='left_anti') \
        .withColumn('cycle', expr('sort_array(cycle)')) \
        .drop_duplicates()
    #+------------+                                                                  
    #|       cycle|
    #+------------+
    #|[1, 2, 3, 4]|
    #|   [2, 3, 5]|
    #|      [6, 7]|
    #+------------+
    
    
