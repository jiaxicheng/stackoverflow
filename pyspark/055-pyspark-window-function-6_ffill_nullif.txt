https://stackoverflow.com/questions/63308490/pyspark-how-to-code-complicated-dataframe-calculation-lead-sum
    
Quick application of Window functions:

  (1) create a sub-group label `g` which take running sum of `int(col1!=-1)`, and we only concern 
      about Rows with col1==1, and nullify all other Rows.
  (2) the residual is 1 and if col1 == -1, plus the running count over `w2`
  (3) take the prev_col1 over `w1` which is not -1 (using nullif), 
      ---
      Note: the naming of prev_col1 might be confusion since it takes only if col1 = -1 using typical 
            pyspark's way to do ffill, otherwise keep the original.
  (4) set val = prev_col1 + residual, take the lag over `w1` and set null to -1

Code:
    
    from pyspark.sql.functions import when, col, expr, count, desc
    from pyspark.sql import Window 
    
    from pyspark.sql import Window
    
    w1 = Window.orderBy(desc('date'))
    w2 = Window.partitionBy('g').orderBy(desc('date')) 
    
    TEST_df.withColumn('g', when(col('col1') == -1, expr("sum(int(col1!=-1))").over(w1))) \
        .withColumn('residual', when(col('col1') == -1, count('*').over(w2) + 1).otherwise(1)) \
        .withColumn('prev_col1',expr("last(nullif(col1,-1),True)").over(w1)) \
        .withColumn('want', coalesce(lag(expr("prev_col1 + residual")).over(w1),lit(-1))) \
        .orderBy('date').show()
    +----------+----+----+--------+---------+----+
    |      date|col1|   g|residual|prev_col1|want|
    +----------+----+----+--------+---------+----+
    |2020-08-01|   3|null|       1|        3|   2|
    |2020-08-02|   1|null|       1|        1|   6|
    |2020-08-03|  -1|   4|       3|        3|   5|
    |2020-08-04|  -1|   4|       2|        3|   4|
    |2020-08-05|   3|null|       1|        3|   8|
    |2020-08-06|  -1|   3|       2|        6|   7|
    |2020-08-07|   6|null|       1|        6|   5|
    |2020-08-08|   4|null|       1|        4|   6|
    |2020-08-09|   5|null|       1|        5|  -1|
    +----------+----+----+--------+---------+----+

Some typical used code patterns:
(1) creating sub-group label `g` using running_sum 
(2) ffill with last(col, True).over(w)
(3) nullif

