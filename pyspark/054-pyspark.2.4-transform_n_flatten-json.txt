https://stackoverflow.com/questions/57285628/spark-error-when-selecting-a-column-from-a-struct-in-a-nested-array

Data Setup:

/path/to/json.file:
{
  "home": {
    "a_number": 5,
    "a_string": "six",
    "array_a": [
      {
        "array_b": [{"a": "1", "b": 2}],
        "struct_c": {"a": 1.1, "b": 1.3},
        "array_d": ["a", "b", "c"]
      },
      {
        "array_b": [{"a": "3", "b": 4}],
        "struct_c": {"a": 1.5, "b": 1.6},
        "array_d": ["x", "y", "z"]
      }
    ]
  }
}

mydf1 = spark.read.option("multiline", "true").json("/path/to/json.file")

mydf1.printSchema()
root
 |-- home: struct (nullable = true)
 |    |-- a_number: long (nullable = true)
 |    |-- a_string: string (nullable = true)
 |    |-- array_a: array (nullable = true)
 |    |    |-- element: struct (containsNull = true)
 |    |    |    |-- array_b: array (nullable = true)
 |    |    |    |    |-- element: struct (containsNull = true)
 |    |    |    |    |    |-- a: string (nullable = true)
 |    |    |    |    |    |-- b: long (nullable = true)
 |    |    |    |-- array_d: array (nullable = true)
 |    |    |    |    |-- element: string (containsNull = true)
 |    |    |    |-- struct_c: struct (nullable = true)
 |    |    |    |    |-- a: double (nullable = true)
 |    |    |    |    |-- b: double (nullable = true)


(1) For spark 2.4+, use Spark SQL built-in functions: transform + flatten:

    >>> mydf1.selectExpr('flatten(transform(home.array_a.array_b, x -> x.a)) as array_field_inside_array').show()
    +------------------------+
    |array_field_inside_array|
    +------------------------+
    |                  [1, 3]|
    +------------------------+

Where we use **transform()** function to retrieve the values of field `a` of each array element of `home.array_a.array_b` and transform them to the array `[[1], [3]]`. then flatten this array into [1, 3]. If you need the result to be `[[1, 3]]`, then just add array() function

    array(flatten(transform(home.array_a.array_b, x -> x.a)))


(2) For Spark 2.4+, use flatten and then dot notation:

    >>> mydf1.selectExpr('flatten(home.array_a.array_b).a as array_field_inside_array').show()
    +------------------------+
    |array_field_inside_array|
    +------------------------+
    |                  [1, 3]|
    +------------------------+

Note: the argument of flatten() function must be an array of arrays. flatten(home.array_a) will yield ERROR since
home.array_a is an array of structs

(3) For Spark < 2.4, get_json_object + from_json + flatten:

    from pyspark.sql.functions import flatten, to_json, from_json, get_json_object

    new_df = mydf1.withColumn('home_json', F.to_json('home')) \
                  .select(flatten(
                          from_json(get_json_object('home_json', '$.array_a[*].array_b[*].a')
                                  , u'array<array<string>>')
                      ).alias('array_field_inside_array')
                  )

    >>> new_df.show()
    +------------------------+
    |array_field_inside_array|
    +------------------------+
    |                  [1, 3]|
    +------------------------+

