https://stackoverflow.com/questions/56931256/how-to-explode-multiple-columns-different-types-and-different-lengths

Setup
-----

    from pyspark.sql import functions as F, Row

    df = spark.createDataFrame([
          Row(a=1, b=[1, 2, 3, 4, 5, 6], c=['11', '22', '33'], d=['foo'], e=[1,2,3])
        , Row(a=2, b=[], c=[], d=[], e=[111,222])
    ])
        
    >>> df.show()
    +---+------------------+------------+-----+----------+
    |  a|                 b|           c|    d|         e|
    +---+------------------+------------+-----+----------+
    |  1|[1, 2, 3, 4, 5, 6]|[11, 22, 33]|[foo]| [1, 2, 3]|
    |  2|                []|          []|   []|[111, 222]|
    +---+------------------+------------+-----+----------+

    # columns required to explode
    cols = df.columns

    # number of elements to set
    N = 6
 
Method-2: Using SQL higher-order function: [transform][1]
-----------------------------------------------
Use the Spark SQL higher-order function: transform(), do the following:

1. create the following Spark SQL code where **`{0}`** will be replaced by the column_name:

        stmt = '''
            CASE
              WHEN '{0}' in ('d') THEN
                transform(sequence(0,{1}-1), x -> IF(x == 1, `{0}`[0], NULL))
              WHEN size(`{0}`) <= {1}/2 THEN
                transform(sequence(0,{1}-1), x -> IF(((x+1)*size(`{0}`))%{1} == 0, `{0}`[int((x-1)*size(`{0}`)/{1})], NULL)) 
              ELSE `{0}`
            END AS `{0}`
        '''

    **Note:** array transformation only defined when array contains <= N/2 elements (in this example, size <= 3). arrays with other size will be kept as-is. 

3. Run the above SQL with **selectExpr()** for all computed columns

        df1 = df.withColumn('a', F.array('a')) \
                .selectExpr(*[ stmt.format(c,N) for c in cols ])

        >>> df1.show()
        +---------+------------------+----------------+-----------+---------------+
        |        a|                 b|               c|          d|              e|
        +---------+------------------+----------------+-----------+---------------+
        |[,,,,, 1]|[1, 2, 3, 4, 5, 6]|[, 11,, 22,, 33]|[, foo,,,,]|  [, 1,, 2,, 3]|
        |[,,,,, 2]|           [,,,,,]|         [,,,,,]|    [,,,,,]|[,, 111,,, 222]|
        +---------+------------------+----------------+-----------+---------------+

4. run **arrays_zip** and **explode**:

        df_new = df1.withColumn('vals', F.explode(F.arrays_zip(*cols))) \
                    .select('vals.*') \
                    .fillna('', subset=cols)

        >>> df_new.show()
        +----+----+---+---+----+
        |   a|   b|  c|  d|   e|
        +----+----+---+---+----+
        |null|   1|   |   |null|
        |null|   2| 11|foo|   1|
        |null|   3|   |   |null|
        |null|   4| 22|   |   2|
        |null|   5|   |   |null|
        |   1|   6| 33|   |   3|
        |null|null|   |   |null|
        |null|null|   |   |null|
        |null|null|   |   | 111|
        |null|null|   |   |null|
        |null|null|   |   |null|
        |   2|null|   |   | 222|
        +----+----+---+---+----+


    **Note**: `fillna('', subset=cols)` only changed columns containing Strings

In one method chain:
--------------------

    df_new = df.withColumn('a', F.array('a')) \
               .selectExpr(*[ stmt.format(c,N) for c in cols ]) \
               .withColumn('vals', F.explode(F.arrays_zip(*cols))) \
               .select('vals.*') \
               .fillna('', subset=cols)


*** Explanation with the transform function***

The transform function (list below, reflect to an old revision of requirements)

    transform(sequence(0,5), x -> IF((x*size({0}))%6 == 0, {0}[int(x*size({0})/6)], NULL))

As mentioned in the post, {0} will be replaced with column name. Here we use column-c which 
contains 3 elements as an example:

* In the transform function, sequence(0,5) yields a constant array `array(0,1,2,3,4,5)` with 6-elements, and the rest sets the lambda function with one argument `x` having the value of elements.

* IF(condition, true_value, false_value): is a standard SQL function

* The condition we applied is: (x*size(c))%6 == 0 where size(c)=3, if this condition is true, it will return c[int(x*size(c)/6)], otherwise, return NULL. so for x from 0 to 5, we will have:

    ((0*3)%6)==0) true   -->  c[int(0*3/6)] = c[0]
    ((1*3)%6)==0) false  -->  NULL
    ((2*3)%6)==0) true   -->  c[int(2*3/6)] = c[1]
    ((3*3)%6)==0) false  -->  NULL
    ((4*3)%6)==0) true   -->  c[int(4*3/6)] = c[2]
    ((5*3)%6)==0) false  -->  NULL

Similar to column-e which contains a 2-element array. 

[1]: https://docs.databricks.com/_static/notebooks/apache-spark-2.4-functions.html

